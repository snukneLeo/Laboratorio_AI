{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-LAB SESSION 2: Informed search\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "## Maze environments\n",
    "\n",
    "The environments used are again **SmallMaze** (visible in the figure) and its variations\n",
    "![SmallMaze](images/maze.png)\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$\n",
    "\n",
    "## Priority Fringe\n",
    "\n",
    "You will need a queue ordered by priority as fringe, or **PriorityFringe**. The difference between the other versions of fringe is that in **PriorityFringe** nodes are removed from the fringe based on the current lowest value. In particular, **FringeNode** has two useful parameters (other than those used in the previous session):\n",
    "* *pathcost* - the path cost from the root node to the current one (defaults to 0)\n",
    "* *value* - value of a node. Used by **PriorityFringe** to order its content (defaults to 0)\n",
    "\n",
    "Here is an example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed: 1\n",
      "Removed: 3\n",
      "Removed: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from utils.fringe import FringeNode, PriorityFringe\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = FringeNode(1) # No parent, pathcost=0, value=0\n",
    "node_2 = FringeNode(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, value=10\n",
    "node_3 = FringeNode(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_fringe = PriorityFringe()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_fringe.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_fringe.is_empty():\n",
    "    print(\"Removed: {}\".format(p_fringe.remove().state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the fringe\n",
    "\n",
    "## Uniform-Cost Search (UCS)\n",
    "\n",
    "Before moving to informed search it is useful to see another uninformed search algorithm: the Uniform-Cost Search (UCS). In the following you can see the implementation in *tree search* version. Cost of performing an action is supposd to be 1 (also in the assignements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "Solution: [(0, 1), (1, 1), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import envs\n",
    "from utils.funcs import build_path\n",
    "\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None\n",
    "        node = fringe.remove()  # Retrieve node from the fringe\n",
    "        if node.state == environment.goalstate:  # Goal state check\n",
    "            return build_path(node)\n",
    "        for action in range(environment.action_space.n):  # Look around\n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = FringeNode(environment.sample(node.state, action), node, node.pathcost + 1, node.pathcost + 1)\n",
    "            fringe.add(child)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution = ucs(env)\n",
    "\n",
    "# Print path\n",
    "print(\"\\nSolution: {}\".format([env.state_to_pos(s) for s in solution]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to be used in order to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "* *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates\n",
    "* *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates\n",
    "* *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to L1 norm but diagonal moves are also considered\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "import utils.heuristics as heu\n",
    "\n",
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you are required to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use *L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by *greedy* must be a tuple $(path, stats)$ in the following form:\n",
    "* *path* - tuple of state identifiers forming a path from the start state to the goal state. ``None`` if no solution is found\n",
    "* *stats* - tuple of:\n",
    "     * *time* - time elapsed between the start and the end of the algorithm\n",
    "     * *expc* - number of nodes explored. A node is considered as explored when removed from the fringe and analyzed\n",
    "     * *maxnodes* - maximum number of nodes in memory at the same time (fringe + closed)\n",
    "\n",
    "After the correctness of your implementations have been assessed, you can run the algorithms on other two maze environments: **GrdMaze** and **BlockedMaze**.\n",
    "\n",
    "The next two functions have to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(env):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe() #mette davanti i valori più bassi\n",
    "    fringe.add(FringeNode(env.startstate))\n",
    "    i = 1\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (0, 0)\n",
    "        node = fringe.remove()\n",
    "        if node.state == env.goalstate:\n",
    "            return build_path(node),(i,len(fringe) + 1)\n",
    "        else:\n",
    "            for action in range(env.action_space.n):\n",
    "                next_state = env.sample(node.state, action)\n",
    "                child = FringeNode(next_state, node, node.pathcost + 1, heu.l1_norm(env.state_to_pos(next_state), env.state_to_pos(env.goalstate)))\n",
    "                fringe.add(child)  \n",
    "                #child = FringeNode(env.sample(node.state, action), node,heu.l1_norm(env.state_to_pos(node.state), env.state_to_pos(env.sample(node.state, action))))\n",
    "                #child = FringeNode(next_state, node, node.pathcost + 1, heu.l1_norm(env.state_to_pos(next_state), env.state_to_pos(goal)))\n",
    "                #fringe.add(child)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    mem = 0\n",
    "    \n",
    "    goal = environment.goalstate\n",
    "    \n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    \n",
    "    closed = []\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (i,mem)\n",
    "        \n",
    "        node = fringe.remove()   \n",
    "        if node.state == environment.goalstate:\n",
    "            return build_path(node), (i+1,mem)\n",
    "        i+=1\n",
    "        if node.state not in closed :  \n",
    "            closed.append(node.state)\n",
    "            for action in range(environment.action_space.n):  \n",
    "                next_state = environment.sample(node.state, action)\n",
    "                child = FringeNode(next_state, node, node.pathcost + 1, heu.l1_norm(environment.state_to_pos(next_state), environment.state_to_pos(env.goalstate)))\n",
    "                fringe.add(child)        \n",
    "            if mem < (len(fringe)+len(closed)):\n",
    "                mem = (len(fringe)+len(closed))\n",
    "    \n",
    "    return None, (i, mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, search_type):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (time, expc, maxnodes): elapsed time, number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    t = timer()\n",
    "    path, stats = search_type(environment)\n",
    "    return path, (timer() - t, stats[0], stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search version of Greedy-best-first search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGRAPH SEARCH\n",
      "\tEnvironment:  BlockedMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'C' 'W' 'W']\n",
      " ['C' 'C' 'W' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.0062s\n",
      "N° of nodes explored: 61\n",
      "Max n° of nodes in memory: 24\n",
      "Solution: None\n"
     ]
    }
   ],
   "source": [
    "envname = \"BlockedMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGRAPH SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "#CORRETTO##\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = greedy(env, greedy_graph_search)  # Perform Greedy-best-first search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tTREE SEARCH\n",
      "\tEnvironment:  BlockedMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'C' 'W' 'W']\n",
      " ['C' 'C' 'W' 'G']]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bb1c75d826bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy_tree_search\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform Greedy-best-first search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ab136a397456>\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(environment, search_type)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0155853884ba>\u001b[0m in \u001b[0;36mgreedy_tree_search\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFringeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathcost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoalstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mfringe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/University/Laboratorio_AI/ai-lab/envs/obsgrid_env.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mreached\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstaterange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai-lab/lib/python3.7/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0m_finfo_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "envname = \"BlockedMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tTREE SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "##CORRETTO###\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = greedy(env, greedy_tree_search)  # Perform Greedy-best-first search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for Greedy-best-first tree search can be found [here](results/greedy_tree_search_results.txt)\n",
    "\n",
    "The following code calls your graph search version of Greedy-best-first search and prints the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for Greedy-best-first graph search can be found [here](results/greedy_graph_search_results.txt)\n",
    "\n",
    "## Assignment 2\n",
    "\n",
    "The second assignment is to implement the A* search algorithm on **SmallMaze**. In particular, you are required to implement both *astar_tree_search* and *astar_graph_search* versions that will be called by the generic *astar*. Use *L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by *astar* must be a tuple $(path, stats)$ in the following form:\n",
    "* *path* - tuple of state identifiers forming a path from the start state to the goal state. ``None`` if no solution is found\n",
    "* *stats* - tuple of:\n",
    "     * *time* - time elapsed between the start and the end of the algorithm\n",
    "     * *expc* - number of nodes explored. A node is considered as explored when removed from the fringe and analyzed\n",
    "     * *maxnodes* - maximum number of nodes in memory at the same time (fringe + closed)\n",
    "\n",
    "After the correctness of your implementations have been assessed, you can run the algorithms on other two maze environments: **GrdMaze** and **BlockedMaze**.\n",
    "\n",
    "The next two functions have to be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    fringe = PriorityFringe() #mette davanti i valori più bassi\n",
    "    fringe.add(FringeNode(env.startstate))\n",
    "    i = 1\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (0, 0)\n",
    "        node = fringe.remove()\n",
    "        if node.state == env.goalstate:\n",
    "            return build_path(node),(i,len(fringe) + 1)\n",
    "        for action in range(env.action_space.n):\n",
    "            child = FringeNode(env.sample(node.state, action), node,node.pathcost + 1, heu.l1_norm(env.state_to_pos(env.sample(node.state, action)), env.state_to_pos(env.goalstate)) + node.pathcost + 1)\n",
    "            fringe.add(child)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment):\n",
    "    \"\"\"\n",
    "    A* Graph search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (expc, maxnodes): number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    m_node = 0\n",
    "    closed = []\n",
    "    \n",
    "    goal = environment.goalstate\n",
    "    \n",
    "    fringe = PriorityFringe()\n",
    "    fringe.add(FringeNode(environment.startstate))\n",
    "    while True:\n",
    "        if fringe.is_empty():\n",
    "            return None, (i,m_node)\n",
    "        node = fringe.remove()\n",
    "        i+=1\n",
    "        if node.state == environment.goalstate : \n",
    "            return build_path(node), (i,m_node)\n",
    "        if node.state not in closed :\n",
    "            closed.append(node.state)\n",
    "            node.pathcost += 1\n",
    "            for action in range(environment.action_space.n): \n",
    "                next_state = environment.sample(node.state, action)\n",
    "                h = heu.l1_norm(environment.state_to_pos(next_state),environment.state_to_pos(goal))\n",
    "                child = FringeNode(next_state, node, node.pathcost, h + node.pathcost)\n",
    "                fringe.add(child)\n",
    "            #m_node = max(m_node, len(closed))\n",
    "            if m_node < (len(fringe) + len(closed)):\n",
    "                m_node = len(fringe) + len(closed)\n",
    "\n",
    "    return None, (i, m_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, stats): solution as a path and stats.\n",
    "        The stats are a tuple of (time, expc, maxnodes): elapsed time, number of explored nodes, max nodes in memory\n",
    "    \"\"\"\n",
    "    t = timer()\n",
    "    path, stats = search_type(environment)\n",
    "    return path, (timer() - t, stats[0], stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search version of A* search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tTREE SEARCH\n",
      "\tEnvironment:  BlockedMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'C' 'W' 'W']\n",
      " ['C' 'C' 'W' 'G']]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e8e903213195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mastar_tree_search\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform A* search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8f7439b40f11>\u001b[0m in \u001b[0;36mastar\u001b[0;34m(environment, search_type)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a090ab7fcbf0>\u001b[0m in \u001b[0;36mastar_tree_search\u001b[0;34m(environment)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfringe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFringeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathcost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoalstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathcost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mfringe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/University/AI_IARTIFICIAL_INTELLIGENCE/ai-lab/envs/obsgrid_env.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mreached\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstaterange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "envname = \"BlockedMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tTREE SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "##CORRETTO###\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = astar(env, astar_tree_search)  # Perform A* search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for A* tree search can be found [here](results/astar_tree_search_results.txt)\n",
    "\n",
    "The following code calls your graph search version of A* search and prints the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGRAPH SEARCH\n",
      "\tEnvironment:  SmallMaze-v0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\n",
      "Execution time: 0.0062s\n",
      "N° of nodes explored: 43\n",
      "Max n° of nodes in memory: 34\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"  # Other options are GrdMaze-v0 and BlockedMaze-v0\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGRAPH SEARCH\")\n",
    "print(\"\\tEnvironment: \", envname)\n",
    "print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "##CORRETTO###\n",
    "\n",
    "# Create and render the environment\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "solution, stats = astar(env, astar_graph_search)  # Perform A* search\n",
    "if solution is not None:\n",
    "    solution = [env.state_to_pos(s) for s in solution]\n",
    "    \n",
    "# Print stats and path\n",
    "print(\"\\n\\nExecution time: {0}s\\nN° of nodes explored: {1}\\nMax n° of nodes in memory: {2}\\nSolution: {3}\".format(\n",
    "        round(stats[0], 4), stats[1], stats[2], solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for A* graph search can be found [here](results/astar_graph_search_results.txt)\n",
    "\n",
    "## Discussion\n",
    "\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
